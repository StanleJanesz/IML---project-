{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54913130-01b4-4efd-96d0-a2ad96fb4896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import torchvision.transforms.v2\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05823567-8b1e-49d4-9499-f66e90a268e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea1b902-54c0-413e-bdca-72c4560a3186",
   "metadata": {},
   "source": [
    "Funkcja do oceniania dokładności modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc81b007-24dd-4c8c-ab68-4d25aca0e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    classes = (\"0\", \"1\")\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    correct_pred = {classname: 0 for classname in classes}\n",
    "    total_pred = {classname: 0 for classname in classes}\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            # collect the correct predictions for each class\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction:\n",
    "                    correct_pred[classes[label]] += 1\n",
    "                total_pred[classes[label]] += 1\n",
    "\n",
    "    print(f'Accuracy of the network on the 1000 test images: {100 * correct // total} %')\n",
    "    # print accuracy for each class\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %, correct: {correct_count}, total: {total_pred[classname]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20796cff-8fc9-4eb9-b530-fdf512782db9",
   "metadata": {},
   "source": [
    "Funkcja obliczająca macro-averaged f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85066162-98e0-4905-b792-075ef5f2ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1(correct_one, total_one, correct_zero, total_zero):\n",
    "    # Calculate precision, recall, and F1 score for class 0\n",
    "    true_positive_0 = correct_zero\n",
    "    false_positive_0 = total_one - correct_one\n",
    "    false_negative_0 = total_zero - correct_zero\n",
    "\n",
    "    precision_0 = true_positive_0 / (true_positive_0 + false_positive_0)\n",
    "    recall_0 = true_positive_0 / (true_positive_0 + false_negative_0)\n",
    "    f1_score_0 = 2 * (precision_0 * recall_0) / (precision_0 + recall_0)\n",
    "\n",
    "    # Calculate precision, recall, and F1 score for class 1\n",
    "    true_positive_1 = correct_one\n",
    "    false_positive_1 = false_negative_0 \n",
    "    false_negative_1 = false_positive_0\n",
    "\n",
    "    precision_1 = true_positive_1 / (true_positive_1 + false_positive_1)\n",
    "    recall_1 = true_positive_1 / (true_positive_1 + false_negative_1)\n",
    "    f1_score_1 = 2 * (precision_1 * recall_1) / (precision_1 + recall_1)\n",
    "\n",
    "    # Calculate macro average F1 score\n",
    "    macro_avg_f1_score = (f1_score_0 + f1_score_1) / 2\n",
    "\n",
    "    return macro_avg_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7da77916-bd6e-47cb-aa56-664f67363a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "classes = (\"0\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ef8c830-1ad0-491e-9fb6-4551e386b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.v2.Compose([transforms.Resize((96, 194)),transforms.v2.ToImage(),\\\n",
    "                                               transforms.v2.ToDtype(torch.float32, scale=True),\\\n",
    "                                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05286576-fbe1-4234-b799-519c75bca3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_cropped_training\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_cropped_training\\\\Images\"\\\n",
    "                       , transform = transform)\n",
    "\n",
    "testset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_cropped_test\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_cropped_test\\\\Images\"\\\n",
    "                      , transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d5a92d2-a429-416c-b976-eecb8fde4d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6830dc7-9928-4496-8437-9fb697038e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),  # (N, 32, 64, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 32, 32, 32)\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # (N, 64, 32, 32)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 64, 16, 16)\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),  # (N, 128, 16, 16)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # (N, 128, 8, 8)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(36864, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549d9127-3891-49c4-bf86-bb04ef475bf6",
   "metadata": {},
   "source": [
    "Spectrograms mel, 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9fa7545d-1bda-4f1b-aba8-7734768cb6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../work_folder/model_4.pth'\n",
    "net = Net(2)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44c9a48a-2457-488d-bd7e-06c4ca96f16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 91 %\n",
      "Accuracy for class: 0     is 97.9 %, correct: 9949, total: 10166\n",
      "Accuracy for class: 1     is 77.4 %, correct: 3519, total: 4549\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eb3d48b5-e648-463e-a317-e8d07e1c789e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8952566360416545"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(3519, 4549, 9949, 10166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "555d2141-36ac-47ca-ad6e-66676a09f2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 81177 training images: 92 %\n",
      "Accuracy for class: 0     is 98.8 %, correct: 55459, total: 56130\n",
      "Accuracy for class: 1     is 78.3 %, correct: 19604, total: 25047\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cb0cd915-4a1b-4d19-b878-d938abbb8eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9064282528926193"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(19604, 25047, 55459, 56130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "498968cd-dc17-4d0c-895a-ba51b8c7be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_cropped_training\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_cropped_training\\\\Images\"\\\n",
    "                       , transform = transform)\n",
    "\n",
    "testset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_cropped_test\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_cropped_test\\\\Images\"\\\n",
    "                      , transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9e2d4c28-4a9b-454e-9a2b-542a19cbc0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8e5b81-b977-403d-9b3a-a0a2163ceb0b",
   "metadata": {},
   "source": [
    "Spectrograms 2 (logarithmic scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2fd27afe-4e5c-4ad1-b85f-a5a6e53dd4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../work_folder/model_5.pth'\n",
    "net = Net(2)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14114f2f-503b-42b8-b43e-dea7fb3b5c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 94 %\n",
      "Accuracy for class: 0     is 95.7 %, correct: 9662, total: 10096\n",
      "Accuracy for class: 1     is 93.1 %, correct: 4236, total: 4549\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a21f3b5c-fecc-4ce0-92fc-9e6cf17b8012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9408769061825313"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(4236, 4549, 9662, 10096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "41e02f13-c88b-46bd-a198-31261cb228af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 81177 training images: 96 %\n",
      "Accuracy for class: 0     is 97.4 %, correct: 54696, total: 56141\n",
      "Accuracy for class: 1     is 93.7 %, correct: 23455, total: 25036\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a98da191-ab04-4be6-bde9-f64db0acaaec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9562425187735828"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(23455, 25036, 54696, 56141)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9d6390ce-533c-403e-9228-3fed0e97b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_cropped_training\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_cropped_training\\\\Images\"\\\n",
    "                       , transform = transform)\n",
    "\n",
    "testset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_cropped_test\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_cropped_test\\\\Images\"\\\n",
    "                      , transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3da18541-4104-4973-b758-2123ea3051ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b8ceb-9b14-45c5-83cc-4650d0cb7d8c",
   "metadata": {},
   "source": [
    "Spectrograms (linear scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5887fa64-23e9-47bd-be89-06957c5463f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../work_folder/model_6.pth'\n",
    "net = Net(2)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1824ae28-b0f0-4a6a-a19d-d9901951f085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 88 %\n",
      "Accuracy for class: 0     is 90.0 %, correct: 9146, total: 10166\n",
      "Accuracy for class: 1     is 84.9 %, correct: 3800, total: 4476\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fed24555-ca4c-44cc-b306-182956c0428e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.866352513745769"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(3800, 4476, 9146, 10166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e905367a-5da8-48fb-9200-92a180b96e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 81328 training images: 88 %\n",
      "Accuracy for class: 0     is 91.4 %, correct: 51614, total: 56477\n",
      "Accuracy for class: 1     is 83.4 %, correct: 20729, total: 24851\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e2a06a03-71b3-40d5-a5b2-7b603060b478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8709036114921318"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(20729, 24851, 51614, 56477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3449f587-9bd5-4dfd-9042-2ad274c04c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_16_cropped_training\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_16_cropped_training\\\\Images\"\\\n",
    "                       , transform = transform)\n",
    "\n",
    "testset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_16_cropped_test\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_16_cropped_test\\\\Images\"\\\n",
    "                      , transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1429a927-4f1d-45b8-b59d-d23c9f706c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9204ca1e-807a-4a04-9f96-6f271497b8f3",
   "metadata": {},
   "source": [
    "Spectrograms 2 (16000 sampling rate), 4 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "957f33c7-9fcc-493d-8bfa-f4bca9fb5756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../work_folder/model_9.pth'\n",
    "net = Net(2)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "961dcc03-3e92-460b-aac4-f415570a34da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 93 %\n",
      "Accuracy for class: 0     is 95.1 %, correct: 9665, total: 10166\n",
      "Accuracy for class: 1     is 91.1 %, correct: 4146, total: 4549\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04b6dd09-3126-413c-a399-9864015419eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285095569311865"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(4146, 4549, 9665, 10166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7365b136-b982-4531-9b1b-6646eb954ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 96 %\n",
      "Accuracy for class: 0     is 97.0 %, correct: 54785, total: 56477\n",
      "Accuracy for class: 1     is 94.9 %, correct: 23771, total: 25047\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6645b0a-be06-4a44-ab08-489ff82f5d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9574330223200017"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(23771, 25047, 54785, 56477)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566b0e06-221c-40d7-9852-cee0ad59e975",
   "metadata": {},
   "source": [
    "Spectrograms 2 (16000 sampling rate), 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae7c87df-72ca-4650-aeb2-46699ff086a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../work_folder/model_10.pth'\n",
    "net = Net(2)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81654d49-16a0-4fac-9c77-07afbdd319bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 95 %\n",
      "Accuracy for class: 0     is 97.6 %, correct: 9918, total: 10166\n",
      "Accuracy for class: 1     is 92.5 %, correct: 4207, total: 4549\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b70513a-a8e9-49b2-8d2d-cfccfac9d10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9527944062895248"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(4207, 4549, 9918, 10166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b995e57-9c78-4fb2-a53b-ad77ac49d328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 98 %\n",
      "Accuracy for class: 0     is 99.2 %, correct: 56022, total: 56477\n",
      "Accuracy for class: 1     is 97.1 %, correct: 24320, total: 25047\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4969f457-8c85-4977-86e0-6b7866124784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9829181212656668"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(24320, 25047, 56022, 56477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e61dc92-e007-497c-af65-ce3b753ddebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_cropped_training\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_cropped_training\\\\Images\"\\\n",
    "                       , transform = transform)\n",
    "\n",
    "testset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_cropped_test\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_cropped_test\\\\Images\"\\\n",
    "                      , transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b79c1d86-4ef5-429d-a35e-ddabc99d2f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1c99f8-13d2-4509-9501-3d35289aec4f",
   "metadata": {},
   "source": [
    "Spectrograms mel (16000 sampling rate), 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "109de65c-8d9a-4517-a8d2-5fc54c7bd459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../work_folder/model_11.pth'\n",
    "net = Net(2)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fc0b096-af0d-4675-8ce3-a23f71fc8986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 96 %\n",
      "Accuracy for class: 0     is 97.0 %, correct: 9856, total: 10166\n",
      "Accuracy for class: 1     is 94.2 %, correct: 4286, total: 4549\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b44e7d7-4624-40d4-8dad-da462ac7134a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9545476683881264"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(4286, 4549, 9856, 10166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c93c5db9-883f-49d8-b8b0-33e1da2835ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 98 %\n",
      "Accuracy for class: 0     is 98.9 %, correct: 55864, total: 56477\n",
      "Accuracy for class: 1     is 98.0 %, correct: 24538, total: 25047\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "edbaf781-7601-498b-b6ed-8f308a12976f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9838530552375464"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(24538, 25047, 55864, 56477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "772a2c3a-decf-4abf-8904-8b8e749a9149",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_noise_cropped_training\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_noise_cropped_training\\\\Images\"\\\n",
    "                       , transform = transform)\n",
    "\n",
    "testset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_noise_cropped_test\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_noise_cropped_test\\\\Images\"\\\n",
    "                      , transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb0b316e-c2f6-40b9-ad24-b8a5464cd88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd6e3b-5757-4e31-b10b-7b6e54c227dc",
   "metadata": {},
   "source": [
    "Spectrograms mel (16000 sampling rate), noise removed, 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60c71e28-ddf2-41f1-8759-5b7a7e40dfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../work_folder/model_12.pth'\n",
    "net = Net(2)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe109387-74c4-44db-97f9-badb8322f839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 94 %\n",
      "Accuracy for class: 0     is 96.0 %, correct: 9759, total: 10166\n",
      "Accuracy for class: 1     is 91.3 %, correct: 4154, total: 4549\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "445e6719-3076-4d07-b617-a739695619cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9362481849140427"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(4154, 4549, 9759, 10166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8ef1cdb-0ef0-48fa-885e-f79878c1e5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 98 %\n",
      "Accuracy for class: 0     is 98.7 %, correct: 55727, total: 56477\n",
      "Accuracy for class: 1     is 97.1 %, correct: 24327, total: 25047\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a652d85a-0ac4-4de6-a1aa-8bccd66512e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9788275634324223"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(24327, 25047, 55727, 56477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18186041-ecc8-404b-a299-4c14238205f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_16_noise_cropped_training\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_16_noise_cropped_training\\\\Images\"\\\n",
    "                       , transform = transform)\n",
    "\n",
    "testset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_16_noise_cropped_test\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_16_noise_cropped_test\\\\Images\"\\\n",
    "                      , transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3fdcc7b-8c0c-4883-a1c9-acc055d12bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e95af8-2fd1-4903-aeb5-2ad70ce4b077",
   "metadata": {},
   "source": [
    "Spectrograms 2 (16000 sampling rate), noise removed, 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f8375ad-32a8-439b-896f-e7857449f2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../work_folder/model_13.pth'\n",
    "net = Net(2)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "223dd43e-8922-4cdf-a006-ff2cbd8e8859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 94 %\n",
      "Accuracy for class: 0     is 95.7 %, correct: 9729, total: 10166\n",
      "Accuracy for class: 1     is 91.3 %, correct: 4155, total: 4549\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8aeeef28-0c9a-45aa-b4a5-f1b402ee6381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9340663772129099"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(4155, 4549, 9729, 10166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9f0626a-03b4-4e3e-921e-a760450348be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 98 %\n",
      "Accuracy for class: 0     is 98.7 %, correct: 55743, total: 56477\n",
      "Accuracy for class: 1     is 97.2 %, correct: 24351, total: 25047\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0156d3d-797d-4cdb-90c4-a8d9dd97989c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9794055118907778"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(24351, 25047, 55743, 56477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "829f42e9-8790-413a-b140-71c8475e9f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_cropped_training\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_cropped_training\\\\Images\"\\\n",
    "                       , transform = transform)\n",
    "\n",
    "testset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_cropped_test\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_cropped_test\\\\Images\"\\\n",
    "                      , transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "10c52eda-c2fe-4080-8dfa-4b05183dd45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936ec779-81c1-4189-9172-b6c741417c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),  # (N, 32, 64, 64)\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 32, 32, 32)\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # (N, 64, 32, 32)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 64, 16, 16)\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),  # (N, 128, 16, 16)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # (N, 128, 8, 8)\n",
    "        )\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d2092f-f940-413a-91c6-2005125d59eb",
   "metadata": {},
   "source": [
    "Spectrograms 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "658ec645-a03a-4449-9dba-3d40b8cbc85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../work_folder/model_7.pth'\n",
    "net = Net(2)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56fca9c6-2ccc-4c49-845d-559dc0fed3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 14645 test images: 80 %\n",
      "Accuracy for class: 0     is 88.1 %, correct: 8892, total: 10096\n",
      "Accuracy for class: 1     is 64.4 %, correct: 2928, total: 4549\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "513a8645-9558-4395-af14-63a80fecc562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7687503134664098"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(2928, 4549, 8892, 10096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5158b202-c244-435b-9460-faec02bc1b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 81177 training images: 95 %\n",
      "Accuracy for class: 0     is 96.9 %, correct: 54393, total: 56141\n",
      "Accuracy for class: 1     is 92.2 %, correct: 23089, total: 25036\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d22a58c6-0a7e-4271-b16a-59aa427e779e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.946530911784752"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(23089, 25036, 54393, 56141)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b18c7a0d-11ac-40fd-9c98-fc865be30d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.v2.Compose([transforms.Resize((193, 388)),transforms.v2.ToImage(),\\\n",
    "                                               transforms.v2.ToDtype(torch.float32, scale=True),\\\n",
    "                                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_cropped_training\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_cropped_training\\\\Images\"\\\n",
    "                       , transform = transform)\n",
    "\n",
    "testset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_cropped_test\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms2_cropped_test\\\\Images\"\\\n",
    "                      , transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0f7d58da-2f9f-4ac6-9cb3-b4b3cfab66ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a319648a-034c-41c5-adc9-861edcd101b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),  # (N, 32, 64, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 32, 32, 32)\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # (N, 64, 32, 32)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 64, 16, 16)\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),  # (N, 128, 16, 16)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # (N, 128, 8, 8)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(147456, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e885083-82ae-4970-8d02-7447e0c440df",
   "metadata": {},
   "source": [
    "Spectrograms 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba75dc-1b25-436a-8240-c84dfa548ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../work_folder/model_8.pth'\n",
    "net = Net(2)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7982f93d-a8aa-450e-a557-38b9c0c514bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 14645 test images: 94 %\n",
      "Accuracy for class: 0     is 95.8 %, correct: 9676, total: 10096\n",
      "Accuracy for class: 1     is 92.8 %, correct: 4223, total: 4549\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "04f89b1c-f627-47e2-b59f-ce075c3e7d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9408621752542221"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(4223, 4549, 9676, 10096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "04afd52c-cd55-4d7c-a6f1-c8bb067f45e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 81177 training images: 98 %\n",
      "Accuracy for class: 0     is 98.8 %, correct: 55469, total: 56141\n",
      "Accuracy for class: 1     is 97.1 %, correct: 24310, total: 25036\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "73bb0edd-f200-4e79-ad5e-a0c3d4ac5b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9798026267729204"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(24310, 25036, 55469, 56141)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5820e2e6-2c89-4519-a77a-ede2c422446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.v2.Compose([transforms.Resize((96, 194)),transforms.v2.ToImage(),\\\n",
    "                                               transforms.v2.ToDtype(torch.float32, scale=True),\\\n",
    "                                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "trainset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_cropped_training\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_cropped_training\\\\Images\"\\\n",
    "                       , transform = transform)\n",
    "\n",
    "testset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_cropped_test\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_cropped_test\\\\Images\"\\\n",
    "                      , transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea66d12b-41f8-4704-bf4e-b3d9d3a1a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ab8efca-9042-4ff1-9d67-17fe04b88bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),  # (N, 32, 64, 64)\n",
    "            nn.BatchNorm2d(num_features = 32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 32, 32, 32)\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # (N, 64, 32, 32)\n",
    "            nn.BatchNorm2d(num_features = 64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 64, 16, 16)\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),  # (N, 128, 16, 16)\n",
    "            nn.BatchNorm2d(num_features = 128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # (N, 128, 8, 8)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(36864, 256 * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256 * 4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1487fc50-45cd-4175-af19-88a823dc4068",
   "metadata": {},
   "source": [
    "Spectrograms mel (16000 sampling rate), 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9872ae83-39fb-4a2c-915d-b6b0d4532836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../work_folder/models/model_15.pth'\n",
    "net = Net(2)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0663cfb-d520-4963-ae04-903e57e5a040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 97 %\n",
      "Accuracy for class: 0     is 98.1 %, correct: 9975, total: 10166\n",
      "Accuracy for class: 1     is 94.9 %, correct: 4315, total: 4549\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e83b5d6d-8990-4f7c-915d-3792f5c3b532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9661028547424905"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(4315, 4549, 9975, 10166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8def781f-8ac9-41cc-93ca-7bc810bc5a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 99 %\n",
      "Accuracy for class: 0     is 99.8 %, correct: 56352, total: 56477\n",
      "Accuracy for class: 1     is 97.8 %, correct: 24495, total: 25047\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da152158-eb7e-4663-a3ac-4225579e1125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9901991004633596"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(24495, 25047, 56352, 56477)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2770c60-699e-46e0-b47e-b527037d5be5",
   "metadata": {},
   "source": [
    "Spectrograms mel (16000 sampling rate), 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "675cdd1f-8863-4462-b682-73153c2b006a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../work_folder/models/model_15_3.pth'\n",
    "net = Net(2)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76a88af1-bc83-4527-a94a-c519074f1f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 97 %\n",
      "Accuracy for class: 0     is 98.7 %, correct: 10031, total: 10166\n",
      "Accuracy for class: 1     is 94.4 %, correct: 4293, total: 4549\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30276fc5-fefa-431b-bcdd-3a59f3fc2f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9686636232281892"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(4293, 4549, 10031, 10166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2646260-85fe-4de5-917a-32c698d6874b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 99 %\n",
      "Accuracy for class: 0     is 99.9 %, correct: 56447, total: 56477\n",
      "Accuracy for class: 1     is 99.9 %, correct: 25027, total: 25047\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22199ae6-f3be-4285-afd1-2109d401a79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992796892083392"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(25027, 25047, 56447, 56477)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284e0ab6-4ba9-4bcb-bd13-d3a648250f6d",
   "metadata": {},
   "source": [
    "Spectrograms mel (16000 sampling rate), 60 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f9a8ae0-46ad-47ef-977e-7651f50a6a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../work_folder/models/model_15_6.pth'\n",
    "net = Net(2)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efa3d2cd-7c0f-4a2c-a9e8-2891fefe4d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 97 %\n",
      "Accuracy for class: 0     is 98.7 %, correct: 10033, total: 10166\n",
      "Accuracy for class: 1     is 94.3 %, correct: 4291, total: 4549\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfbeeb67-2bc1-4e9d-9405-62c2e7924a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9686557840407863"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(4291, 4549, 10033, 10166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02045686-0faa-43bc-aaaf-24821c279621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 99 %\n",
      "Accuracy for class: 0     is 100.0 %, correct: 56463, total: 56477\n",
      "Accuracy for class: 1     is 100.0 %, correct: 25039, total: 25047\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c185c9a-2a8d-4038-a34e-baba0aabb8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996830491723991"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(25039, 25047, 56463, 56477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bcd2c8c-3c02-48f5-a58e-2cf837811bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_normalized_cropped_training\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_normalized_cropped_training\\\\Images\"\\\n",
    "                       , transform = transform)\n",
    "\n",
    "testset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_normalized_cropped_test\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_normalized_cropped_test\\\\Images\"\\\n",
    "                      , transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32c79126-4334-4758-a87b-9747a629510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1257d4-cbfa-40ec-bf95-296df378b491",
   "metadata": {},
   "source": [
    "Spectrograms mel (16000 sampling rate), normalized audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d74aa68d-2709-40fd-94bb-bfeb496e336d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../work_folder/model_20.pth'\n",
    "net = Net(2)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6930009-df6b-42d1-bb22-b78dd79ce907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 94 %\n",
      "Accuracy for class: 0     is 96.7 %, correct: 9827, total: 10166\n",
      "Accuracy for class: 1     is 89.2 %, correct: 4056, total: 4549\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8fab570-b8ab-45e4-92b6-424ee07679a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9331818212778324"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(4056, 4549, 9827, 10166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71039fd8-6f49-41b3-82b6-c4d2779bd679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 98 %\n",
      "Accuracy for class: 0     is 99.0 %, correct: 55929, total: 56477\n",
      "Accuracy for class: 1     is 96.4 %, correct: 24138, total: 25047\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6023222b-d9fe-477c-b2c3-0dba2e0b5d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.978922797338458"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(24138, 25047, 55929, 56477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86f6220a-6c34-4f0a-8416-4114b79e6d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),  # (N, 32, 64, 64)\n",
    "            nn.BatchNorm2d(num_features = 32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 32, 32, 32)\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # (N, 64, 32, 32)\n",
    "            nn.BatchNorm2d(num_features = 64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 64, 16, 16)\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),  # (N, 128, 16, 16)\n",
    "            nn.BatchNorm2d(num_features = 128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 128, 8, 8)\n",
    "\n",
    "            nn.Conv2d(128, 512, kernel_size=3, stride=1, padding=1),  # (N, 128, 16, 16)\n",
    "            nn.BatchNorm2d(num_features = 512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # (N, 128, 8, 8)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(36864, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(2048, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76677939-9132-4da3-9292-94dc954849d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../work_folder/model_16.pth'\n",
    "net = Net(2)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fd38fdd-6953-4699-80c3-2d0d384affd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 96 %\n",
      "Accuracy for class: 0     is 98.3 %, correct: 9990, total: 10166\n",
      "Accuracy for class: 1     is 91.5 %, correct: 4162, total: 4549\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48bc8ecd-87da-43cc-b323-88a27d3bc6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9546215544468195"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(4162, 4549, 9990, 10166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88285ea3-6315-42c5-81d9-193820f1b42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 99 %\n",
      "Accuracy for class: 0     is 100.0 %, correct: 56458, total: 56477\n",
      "Accuracy for class: 1     is 99.8 %, correct: 25003, total: 25047\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "664ad377-6c48-4d90-9d85-23031a69385c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990920553251521"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(25003, 25047, 56458, 56477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d5ce00d-af9e-480a-a072-5003cc8a92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),  # (N, 32, 64, 64)\n",
    "            nn.BatchNorm2d(num_features = 32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 32, 32, 32)\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # (N, 64, 32, 32)\n",
    "            nn.BatchNorm2d(num_features = 64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 64, 16, 16)\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),  # (N, 128, 16, 16)\n",
    "            nn.BatchNorm2d(num_features = 128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 128, 8, 8)\n",
    "\n",
    "            nn.Conv2d(128, 512, kernel_size=3, stride=1, padding=1),  # (N, 128, 16, 16)\n",
    "            nn.BatchNorm2d(num_features = 512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # (N, 128, 8, 8)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(36864, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2048, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e752377-a407-477b-ac3d-44d5d9d86db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../work_folder/model_17.pth'\n",
    "net = Net(2)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b631227f-abfb-4d00-8f29-48677b0afcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 96 %\n",
      "Accuracy for class: 0     is 97.4 %, correct: 9903, total: 10166\n",
      "Accuracy for class: 1     is 94.4 %, correct: 4296, total: 4549\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eaecbc29-bd33-4b8c-9978-7eb5b72f0ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9589776534552596"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(4296, 4549, 9903, 10166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ac13647-b023-4558-9d26-80ce80873b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 99 %\n",
      "Accuracy for class: 0     is 99.9 %, correct: 56403, total: 56477\n",
      "Accuracy for class: 1     is 99.9 %, correct: 25014, total: 25047\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a785d17c-c792-4340-8f95-b708b0a6073f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9984590650967857"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(25014, 25047, 56403, 56477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6dc7e929-0772-4572-9a2f-06aaf162f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),  # (N, 32, 64, 64)\n",
    "            nn.BatchNorm2d(num_features = 32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 32, 32, 32)\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # (N, 64, 32, 32)\n",
    "            nn.BatchNorm2d(num_features = 64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 64, 16, 16)\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),  # (N, 128, 16, 16)\n",
    "            nn.BatchNorm2d(num_features = 128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 128, 8, 8)\n",
    "\n",
    "            nn.Conv2d(128, 512, kernel_size=3, stride=1, padding=1),  # (N, 128, 16, 16)\n",
    "            nn.BatchNorm2d(num_features = 512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # (N, 128, 8, 8)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(36864, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e831c2c-513b-4618-963a-bdfe68d7f82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../work_folder/models/model_18.pth'\n",
    "net = Net(2)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92c07435-6e58-4e6b-a286-ea0a568e309e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 96 %\n",
      "Accuracy for class: 0     is 97.5 %, correct: 9911, total: 10166\n",
      "Accuracy for class: 1     is 92.8 %, correct: 4223, total: 4549\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a765bddc-38c6-4607-9ca6-cc90638738e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9535806636845822"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(4223, 4549, 9911, 10166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b164936b-f245-4a7a-a54f-1312c820291c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 99 %\n",
      "Accuracy for class: 0     is 100.0 %, correct: 56462, total: 56477\n",
      "Accuracy for class: 1     is 99.9 %, correct: 25021, total: 25047\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e12be6d2-e0f3-4df0-b707-7dda4cd7b81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994092073346887"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(25021, 25047, 56462, 56477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d7b989e-ef3e-4dc3-a77a-fdb67c89b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.v2.Compose([transforms.Resize((64, 64)),transforms.v2.ToImage(),\\\n",
    "                                               transforms.v2.ToDtype(torch.float32, scale=True),\\\n",
    "                                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "trainset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_cropped_training\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_cropped_training\\\\Images\"\\\n",
    "                       , transform = transform)\n",
    "\n",
    "testset = ImageDataset(annotations_file = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_cropped_test\\\\labels.csv\", img_dir = \"..\\\\work_folder\\\\daps_Data\\\\Spectrograms_mel_16_cropped_test\\\\Images\"\\\n",
    "                      , transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7eaa84a0-8eb2-4a55-ad9e-e0f6815143b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5e10a1a-2a9c-4b68-816a-fd9b8dc90e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),  # (N, 32, 64, 64)\n",
    "            nn.BatchNorm2d(num_features = 32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 32, 32, 32)\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # (N, 64, 32, 32)\n",
    "            nn.BatchNorm2d(num_features = 64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (N, 64, 16, 16)\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),  # (N, 128, 16, 16)\n",
    "            nn.BatchNorm2d(num_features = 128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # (N, 128, 8, 8)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*64*2, 256 * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256 * 4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f4b19ef-f892-48d4-948c-1a88d1a71ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../work_folder/models/model_19.pth'\n",
    "net = Net(2)\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a81d53b4-d210-4236-85c5-e8be0a6b5bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 96 %\n",
      "Accuracy for class: 0     is 97.7 %, correct: 9935, total: 10166\n",
      "Accuracy for class: 1     is 93.0 %, correct: 4230, total: 4549\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c80b4cd9-fc03-4bb6-8ba0-28e134720d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9560111683503256"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(4230, 4549, 9935, 10166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b412eabe-aa39-40b2-9860-bcc8f8b4cd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 99 %\n",
      "Accuracy for class: 0     is 99.8 %, correct: 56341, total: 56477\n",
      "Accuracy for class: 1     is 99.6 %, correct: 24958, total: 25047\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(net, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6e5fa4b9-db74-4b5f-aba6-c049a9fecd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9967599318940576"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1(24958, 25047, 56341, 56477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bfba8f-0ede-4475-bc6e-9f4057810525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
