{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a34fb5fa-c6ce-4797-83af-b37f5268556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adda6ee1-3e69-4d19-8a56-4f9c5250e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "directoryone = \"daps_Data\\\\Class_One\\\\Spectrograms\"\n",
    "directorytwo = \"daps_Data\\\\Class_Two\\\\Spectrograms\"\n",
    "for filename in os.listdir(directoryone):\n",
    "    if 'f10' in filename:\n",
    "        fullpath = os.path.join(directoryone, filename)\n",
    "        shutil.move(fullpath, directorytwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78b24fa6-7a70-4106-b7ea-8ea34bf30fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_directory = \"daps_Data\\\\test_dataset\\\\Images\"\n",
    "training_directory = \"daps_Data\\\\training_dataset\\\\Images\"\n",
    "directoryone = \"daps_Data\\\\Class_One\\\\Spectrograms\"\n",
    "directorytwo = \"daps_Data\\\\Class_Two\\\\Spectrograms\"\n",
    "i = 1\n",
    "a = random.sample(range(1, 1968), 300)\n",
    "for filename in os.listdir(directoryone):\n",
    "    fullpath = os.path.join(directoryone, filename)\n",
    "    if i in a:\n",
    "        shutil.copy(fullpath, test_directory)        \n",
    "    else:\n",
    "        shutil.copy(fullpath, training_directory)\n",
    "    i=i+1\n",
    "i=1\n",
    "a = random.sample(range(1, 4464), 700)\n",
    "for filename in os.listdir(directorytwo):\n",
    "    fullpath = os.path.join(directorytwo, filename)\n",
    "    if i in a:\n",
    "        shutil.copy(fullpath, test_directory)        \n",
    "    else:\n",
    "        shutil.copy(fullpath, training_directory)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a20a25c-9ec9-4421-a785-b81b8694b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of csv file\n",
    "csvname = \"daps_Data\\\\training_dataset\\\\labels.csv\"\n",
    "class_one_indicators = ['f1', 'f7', 'f8', 'm3', 'm6', 'm8']\n",
    "directory = \"daps_Data\\\\training_dataset\\\\images\"\n",
    "# writing to csv file\n",
    "with open(csvname, 'w') as csvfile:\n",
    "    # creating a csv writer object\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    for filename in os.listdir(directory):\n",
    "        if any(indicator in filename for indicator in class_one_indicators) and not 'f10' in filename:\n",
    "            csvwriter.writerow([filename, '1'])\n",
    "        else:\n",
    "            csvwriter.writerow([filename, '0'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e33a448-5fba-42be-91c6-6575b129dbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "training_directory = \"daps_Data\\\\training_dataset\\\\Images\"\n",
    "left = 125\n",
    "top = 60\n",
    "right = 901\n",
    "bottom = 446\n",
    "target = \"daps_Data\\\\training_dataset\\\\Images_cropped\\\\\"\n",
    "# Opens a image in RGB mode\n",
    "for filename in os.listdir(training_directory):\n",
    "    fullpath = os.path.join(training_directory, filename)\n",
    "    im = Image.open(fullpath)\n",
    " \n",
    "# Size of the image in pixels (size of original image)\n",
    "# (This is not mandatory)\n",
    "# width, height = im.size\n",
    " \n",
    "# Setting the points for cropped image\n",
    "\n",
    " \n",
    "# Cropped image of above dimension\n",
    "# (It will not change original image)\n",
    "    im1 = im.crop((left, top, right, bottom))\n",
    "    im1.save(target + filename)\n",
    "# Shows the image in image viewer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e326af79-09ca-4a64-9445-a3341bc1f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e3c7a0a-5024-438b-ad94-cd785ba06a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1227ae2d-63e6-4d79-9823-9b05dc69111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.v2\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2cf27e8-dc3b-4de0-811a-b55b58b98b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.v2.Compose([transforms.v2.ToImage(), transforms.v2.ToDtype(torch.float32, scale=True),\\\n",
    "                                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "trainset = ImageDataset(annotations_file = \"daps_Data\\\\training_dataset\\\\labels.csv\", img_dir = \"daps_Data\\\\training_dataset\\\\Images_cropped\")\n",
    "\n",
    "testset = ImageDataset(annotations_file = \"daps_Data\\\\test_dataset\\\\labels.csv\", img_dir = \"daps_Data\\\\test_dataset\\\\Images_cropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58072d15-0015-4887-a629-c0cffb2b83d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "classes = (\"0\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71c71065-4523-4abe-8860-e8dc32ecba66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.5..127.5].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0     0     0    \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "162bbaa8-2ef4-49d0-bf30-a7d23de80de9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mNet\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m(Net, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Convolution layer C1: 1 input image channel, 6 output channels,\n",
    "        # 5x5 square convolution, it uses RELU activation function, and\n",
    "        # outputs a Tensor with size (N, 6, 28, 28), where N is the size of the batch\n",
    "        c1 = F.relu(self.conv1(input))\n",
    "        # Subsampling layer S2: 2x2 grid, purely functional,\n",
    "        # this layer does not have any parameter, and outputs a (N, 6, 14, 14) Tensor\n",
    "        s2 = F.max_pool2d(c1, (2, 2))\n",
    "        # Convolution layer C3: 6 input channels, 16 output channels,\n",
    "        # 5x5 square convolution, it uses RELU activation function, and\n",
    "        # outputs a (N, 16, 10, 10) Tensor\n",
    "        c3 = F.relu(self.conv2(s2))\n",
    "        # Subsampling layer S4: 2x2 grid, purely functional,\n",
    "        # this layer does not have any parameter, and outputs a (N, 16, 5, 5) Tensor\n",
    "        s4 = F.max_pool2d(c3, 2)\n",
    "        # Flatten operation: purely functional, outputs a (N, 400) Tensor\n",
    "        s4 = torch.flatten(s4, 1)\n",
    "        # Fully connected layer F5: (N, 400) Tensor input,\n",
    "        # and outputs a (N, 120) Tensor, it uses RELU activation function\n",
    "        f5 = F.relu(self.fc1(s4))\n",
    "        # Fully connected layer F6: (N, 120) Tensor input,\n",
    "        # and outputs a (N, 84) Tensor, it uses RELU activation function\n",
    "        f6 = F.relu(self.fc2(f5))\n",
    "        # Gaussian layer OUTPUT: (N, 84) Tensor input, and\n",
    "        # outputs a (N, 10) Tensor\n",
    "        output = self.fc3(f6)\n",
    "        return output\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f2131aa-8658-43d1-8d11-4d53d9688241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8fc4c52-c783-4aba-9a12-da364b864343",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):  \u001b[38;5;66;03m# loop over the dataset multiple times\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;66;03m# get the inputs; data is a list of [inputs, labels]\u001b[39;00m\n",
      "File \u001b[1;32m<stringsource>:69\u001b[0m, in \u001b[0;36mcfunc.to_py.__Pyx_CFunc_b0409f__29_pydevd_sys_monitoring_cython_object__lParen__etc_to_py_4code_4line.wrap\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1428\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._line_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1486\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._internal_line_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1905\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2197\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2194\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2196\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2197\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2199\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2202\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2266\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2263\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[0;32m   2264\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[1;32m-> 2266\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2267\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m   2269\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9558cd4-62ee-4609-8ec8-9df80ef8f68e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
